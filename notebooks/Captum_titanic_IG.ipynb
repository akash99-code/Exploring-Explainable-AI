{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf990a0",
   "metadata": {},
   "source": [
    "## Captum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a319ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423168a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## installation\n",
    "#! pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b456ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fc128",
   "metadata": {},
   "source": [
    "### Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f410b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset.\n",
    "titanic_data = pd.read_csv(\"data/titanic3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f216dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "titanic_data = pd.concat([titanic_data,\n",
    "                          pd.get_dummies(titanic_data['sex']),\n",
    "                          pd.get_dummies(titanic_data['embarked'],prefix=\"embark\"),\n",
    "                          pd.get_dummies(titanic_data['pclass'],prefix=\"class\")], axis=1)\n",
    "titanic_data[\"age\"] = titanic_data[\"age\"].fillna(titanic_data[\"age\"].mean())\n",
    "titanic_data[\"fare\"] = titanic_data[\"fare\"].fillna(titanic_data[\"fare\"].mean())\n",
    "titanic_data = titanic_data.drop(['name','ticket','cabin','boat','body','home.dest','sex','embarked','pclass'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70273b",
   "metadata": {},
   "source": [
    "**Pre-processed data description**\n",
    "\n",
    "* Age - Passenger Age\n",
    "* Sibsp - Number of Siblings / Spouses Aboard\n",
    "* Parch - Number of Parents / Children Aboard\n",
    "* Fare - Fare Amount Paid in British Pounds\n",
    "* Female - Binary variable indicating whether passenger is female\n",
    "* Male - Binary variable indicating whether passenger is male\n",
    "* EmbarkC - Binary variable indicating whether passenger embarked at Cherbourg\n",
    "* EmbarkQ - Binary variable indicating whether passenger embarked at Queenstown\n",
    "* EmbarkS - Binary variable indicating whether passenger embarked at Southampton\n",
    "* Class1 - Binary variable indicating whether passenger was in first class\n",
    "* Class2 - Binary variable indicating whether passenger was in second class\n",
    "* Class3 - Binary variable indicating whether passenger was in third class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ea32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(131254)\n",
    "\n",
    "# Convert features and labels to numpy arrays.\n",
    "labels = titanic_data[\"survived\"].to_numpy()\n",
    "titanic_data = titanic_data.drop(['survived'], axis=1)\n",
    "feature_names = list(titanic_data.columns)\n",
    "data = titanic_data.to_numpy()\n",
    "\n",
    "# Separate training and test sets using \n",
    "train_indices = np.random.choice(len(labels), int(0.7*len(labels)), replace=False)\n",
    "test_indices = list(set(range(len(labels))) - set(train_indices))\n",
    "train_features = data[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "test_features = data[test_indices]\n",
    "test_labels = labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab6e4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Network\n",
    "\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(1)  # Set seed for reproducibility.\n",
    "\n",
    "class TitanicSimpleNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(12, 12)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(12, 8)\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.linear3 = nn.Linear(8, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lin1_out = self.linear1(x)\n",
    "        sigmoid_out1 = self.sigmoid1(lin1_out)\n",
    "        sigmoid_out2 = self.sigmoid2(self.linear2(sigmoid_out1))\n",
    "        return self.softmax(self.linear3(sigmoid_out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "895f970e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 => Loss: 0.70\n",
      "Epoch 21/200 => Loss: 0.55\n",
      "Epoch 41/200 => Loss: 0.50\n",
      "Epoch 61/200 => Loss: 0.49\n",
      "Epoch 81/200 => Loss: 0.48\n",
      "Epoch 101/200 => Loss: 0.49\n",
      "Epoch 121/200 => Loss: 0.48\n",
      "Epoch 141/200 => Loss: 0.48\n",
      "Epoch 161/200 => Loss: 0.48\n",
      "Epoch 181/200 => Loss: 0.48\n"
     ]
    }
   ],
   "source": [
    "## Loading pre-trained model or Training the network\n",
    "net = TitanicSimpleNNModel()\n",
    "USE_PRETRAINED_MODEL = False\n",
    "\n",
    "input_tensor = torch.from_numpy(train_features).type(torch.FloatTensor)\n",
    "label_tensor = torch.from_numpy(train_labels)\n",
    "    \n",
    "if USE_PRETRAINED_MODEL:\n",
    "    net.load_state_dict(torch.load('models/titanic_model.pt'))\n",
    "    print(\"Model Loaded!\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    num_epochs = 200\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.1)  \n",
    "    for epoch in range(num_epochs):    \n",
    "        output = net(input_tensor)\n",
    "        loss = criterion(output, label_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 20 == 0:\n",
    "            print ('Epoch {}/{} => Loss: {:.2f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    torch.save(net.state_dict(), 'models/titanic_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4055b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8427947598253275\n",
      "Test Accuracy: 0.8142493638676844\n"
     ]
    }
   ],
   "source": [
    "## Evaluation\n",
    "\n",
    "out_probs = net(input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Train Accuracy:\", sum(out_classes == train_labels) / len(train_labels))\n",
    "\n",
    "test_input_tensor = torch.from_numpy(test_features).type(torch.FloatTensor)\n",
    "out_probs = net(test_input_tensor).detach().numpy()\n",
    "out_classes = np.argmax(out_probs, axis=1)\n",
    "print(\"Test Accuracy:\", sum(out_classes == test_labels) / len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a496152",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integrated Gradients (Feature Attribution)\n",
    "ig = IntegratedGradients(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beb1c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor.requires_grad_()\n",
    "attr, delta = ig.attribute(test_input_tensor,target=1, return_convergence_delta=True)\n",
    "attr = attr.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df05125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
